\chapter{Τιτλος κεφαλαίου 2}
\section{Αρχες και λοιπά}
Στο δεύτερο κεφάλαιο αναλύουμε σε μεγαλύτερο βάθος το πρόβλημα διατυπώνοντας
τους παράγοντες που το αποτελούν. Επίσης αναφέρουμε σχετική έρευνα από τη
βιβλιογραφία και αναλύουμε έναν σχετικά απλό αλλά αποδοτικό αλγόριθμο από τον
οποίο αναμένουμε καλά αποτελέσματα.

Στο τρίτο κεφάλαιο περιγράφουμε το σύστημα και τις συνθήκες κάτω από τις οποίες
εκτελέστηκαν τα πειράματα, ενώ στο τέταρτο παρουσιάζουμε τα αποτελέσματα. Τέλος
το πέμπτο κεφάλαιο περιέχει μία ανακεφαλαίωση και τα συμπεράσματα της εργασίας
καθώς και μελλοντική δουλειά που μπορεί να γίνει.

Θα γράψουμε για παρόμοιες εργασίες.. Αυτό θα το σπάσουμε σε 2 μέρη:
1) Πως λύνουνε άλλοι γενικά το θέμα του χρονοπρογρ για vm
2) Συγκεκριμένη δουλειά πάνω σε contention aware techniqs
\section{Το πρόβλημα σε βάθος}
Όπως αναφέρθηκε νωρίτερα, ένα από τα μεγαλύτερα προβλήματα που καλείται να
αντιμετωπίσει ένας πάροχος υπηρεσιών είναι αυτό του ανταγωνισμού για κοινούς
πόρους. Όταν κάποιος (πχ μια εταιρεία αποφασίσει να έχει στην ιδιοκτησία του τις
υποδομές στις οποίες θα στηριχθεί, είναι εύκολο να ρυθμίση τη χρήση τους και να
τις μοιράσει στα διάφορα tasks/jobs ανάλογα με τις δικές του ανάγκες. Αυτό
φυσικά γίνεται απλό από τη στιγμή που ο ίδιος ξέρει τί ακριβώς κάνει το κάθε
task, καθώς και τις ανάγκες αυτού. Μπορεί λοιπόν από πριν να αναλύσει τις
δοσοληψίες που θα γίνουν μεταξύ των διεργασιών και δεδομένων των εξαρτήσεων που
ενδεχομένωνς θα παρουσιαστούν μεταξύ τους, να καθορίσει τη σειρά με την οποία
αυτές θα εκτελεστούν ώστε να μειωθεί ο ανταγωνισμός και να αυξηθεί η
συνολική παραγωγικότητα.

Κάτι τέτοιο είναι σαφώς πιο δύσκολο στο περιβάλλον του νέφους και είναι από τους
βασικότερες αιτίες για τις οποίες οι εταιρείες αποφεύγουν αυτή τη λύση. Είναι
υποχρέωση λοιπόν του παρόχου να μπορεί να απομονώσει τις εργασίες που είναι
ιδιαίτερα απαιτητικές και θα επηρεάσουν την απόδοση των υπόλοιπων ώστε να
διασφαλίσει την καλή ποιότητα της υπηρεσίας του. Τα επιμέρους προβλήματα από τα
οποία συνίσταται και το βασικό είναι αρκετά και οι λύσεις τους όχι πάντα
προφανείς.

Στην περίπτωση του IaaS, οι εικονικές μηχανές αντιμετωπίζονται ως μαύρα κουτιά:
δεν είμαστε σε θέση να γνωρίζουμε τί εκτελούν και κατ' επέκταση τις
απαιτήσεις τους σε πόρους. Αυτό έχει ως αποτέλεσμα να μην μπορούμε να
προβλέψουμε από πριν τις επιπτώσεις που θα έχει να δρομολογήσουμε ταυτόχρονα δύο
μηχανές. Αν η επιλογή γίνει με τυχαιοκρατική πολιτική υπάρχει σοβαρή πιθανότητα
οι δύο μηχανές να ανταγωνίζονται είτε για τον δίαυλο προς τη μνήμη είτε για τις
κρυφές μνήμες με αποτέλεσμα η μία να επιβραδύνει σε μεγάλο βαθμό την άλλη. Στην
πραγματικότητα το γεγονός ότι δεν είμαστε σε θέση να ξέρουμε από πριν τη
συμπεριφορά των εικονικών μηχανών έχει ιδιαίτερο βάρος στο συνολικό εγχείρημα.
\subsection{Τεχνικές διαχείρησης νέφους}
Το ζητούμενο του χρονοπρογραμματισμού είναι να αποφασίσουμε πού θα τοποθετηθεί
κάθε VM και πότε θα έρθει στη CPU ώστε να μπορεί να χρησιμοποιήσει αποδοτικά το
σύστημα να επηρεάζει τα υπόλοιπα όσο γίνεται λιγότερο. Για να αποφασίσουμε κάτι
τέτοιο πρέπει να είμαστε σε θέση να ξέρουμε με κάποιο τρόπο τις απαιτήσεις
στους διάφορους πόρους. Για παράδειγμα, γνωρίζοντας πόσο συχνά θα καταφεύγει στη
μνήμη για να φέρει δεδομένα προς επεξεργασία καθώς και σε τί ποσοστό θα τα
επαναχρησιμοποιεί θα ξέρουμε αν είναι ασφαλές να το τοποθετήσουμε δίπλα σε ένα
VM που χρησιμοποιεί πολύ τις κρυφές μνήμες.

Σε κάποιο βαθμό ο εκάστοτε χρήστης/πελάτης μπορεί να βοηθήσει τον
χαρακτηρισμό/την κατηγοριοποίηση του δικού του VM καθώς συνήθως γνωρίζει τη
λειτουργία του. Ωστόσο αυτό δεν αρκεί και πρέπει να έχουμε τρόπο να
χαρακτηρίσουμε με αυτόματο τρόπο μία εικονική μηχανή. Έτσι έχουν προταθεί
διάφορα μοντέλα και τεχνικές που είναι σε θέση να μελετήσουν την ευρύτερη
συμπεριφορά ενός μηχανήματος και με τρόπο δυναμικό και αυτόματο να το
τοποθετήσουν σε ξεχωριστές κλάσεις ανάλογα με τις απαιτήσεις του στους διάφορους
πόρους. Και αν στο μέλλον κριθεί απαραίτητο να αλλάξουν την κλάση του.
<<
ΕΔΩ ΜΠΟΡΟΥΜΕ / ΠΡΕΠΕΙ ΝΑ ΒΑΛΟΥΜΕ ΚΑΙ ΑΝΤΙΣΤΟΙΧΕΣ ΜΕΤΡΗΣΕΙΣ;;; θα μπορούσαμε να
γεμίσουμε μισή με μία σελίδα εύκολα + θα είχε την αντιστοιχη στήριξη το κείμενό
μας! >>
<<Να γραψω για τον τρόπο που πρέπει να μετράμε τα counters για να κάνουμε on the
fly classification.....>>

\subsection{Σημεία ανταγωνισμού}
<<Εδώ θα γράψουμε για τα βασικά σημεία ανταγωνισμού και λίγο περισσότερο για αυτά
που θα αναλύσουμε εμείς (LLC και Memory Bus)>>

Για να αντιμετωπίσουμε το πρόβλημα πρέπει πρώτα να βρούμε τα κυριότερα σημεία
στα οποία συναντάται ο περισσότερος ανταγωνισμός. Πρώτα όμως πρέπει αν
εξηγήσουμε τις βασικές κατηγορίες αρχιτεκτονικών με τις οποίες γίνεται πρόσβαση
στη μνήμη.

\begin{itemize}
	\item \textbf{Uniform Memory Access (UMA)}:

		
	\item \textbf{Non-uniform Memory Access (NUMA)}:

		Μπλα μπλα μπλα μπλα
\end{itemize}

Μελετώντας περισσότερο την αρχιτεκτονική των συστημάτων που χρησιμοποιούνται
παρατηρούμε πως ο κύριος ανταγωνισμός εντοπίζεται σε τρεία σημεία:
\begin{itemize}
	\item τελευταίο επίπεδο cache (llc): Το φαινόμενο κατα το οποίο πολλά
		νήματα ή διεργασίες ανταγωνίζονται για το llc έχει διερευνηθεί
		εκτενώς σε προηγούμενες εργασίες. Η συνηθέστερη πολιτική
		αντικατάστασης που χρησιμοποιούν οι κρυφές μνήμες και έχει
		σημαντικά αποτελέσματα σε μονοπύρηνα συστήματα είναι η LRU.
		Είναι σχεδιασμένη για να αξιοποιεί στο μέγιστο το temporal
		locality αφού φροντίζει να κρατάει στη cache τα δεδομένα που
		έχουν χρησιμοποιηθεί πιο πρόσφατα. Όταν όμως η LLC είναι
		μοιραζόμενη, η πολιτική αυτή αντιμετωπίζει τα misses από όλα τα
		threads με τον ίδιο τρόπο. Κάτι τέτοιο σημαίνει πως όταν ένα
		thread έχει κάποια αστοχία θα φέρει από τη μνήμη δεδομένα και θα
		αντικαταστήσει ένα block το οποίο ενδεχομένως χρησιμοποιείται
		από άλλη διεργασία. Με τον τρόπο αυτό, η λειτουργία μίας
		διεργασίας μπορεί να επηρεάσει σημαντικά την επίδοση των
		γειτονικών της.
	\item Δίαυλος προς την κεντρική μνήμη (Memory bus): Είναι ίσως το
		προφανέστερο σημείο για το οποίο θα υπάρξει ανταγωνισμός. Για
		σχεδιαστικούς λόγους ο δίαυλος μπορεί ανα πάσα στιγμή να
		χρησιμοποιηθεί από περιορισμένο αριθμό διεργασιών. Κάτι τέτοιο
		σημαίνει πως όταν δύο εφαρμογές προσπαθούν να φέρουν δεδομένα
		από τη μνήμη, θα υπάρξουν καθυστερήσεις εξ αιτίας του
		ανταγωνισμού.
	\item DRAM Controller: Blablablabla blabla bla
\end{itemize}

Το φαινόμενο περιορίζεται τόσο στους διαύλους όσο και στους ελεγκτές στις NUMA
αρχιτεκτονικές, καθώς κάθε package έχει δικά του στοιχεία. Ωστόσο όπως έδειξαν
πρόσφατες έρευνες (...) 
στο τελευταίο
επίποδο cache (last level cache-llc) το οποίο είναι μοιραζόμενο μεταξύ των
πυρήνων, στον δίαυλο προς την κεντρική μνήμη (memory bus), καθώς και στον εγεκτή
μνήμης (DRAM Controller).

\subsection{Η απάντηση: Contention-aware scheduler}
Εδώ θα γράψουμε για την γενική ιδέα των contention-aware scheduler και θα
περιγράψουμε κάποιες προσεγγίσεις



\section{Σχετική έρευνα}
Μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα 
μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα 
μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα 
μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα μπλα 
\section{LCA: ένας αποδοτικός χρονοδρομολογητής}
Σαν βασική λύση στο πρόβλημα προτάθηκε ένας αρκετά απλός χρονοδρομολογητής που
είχε υποσχόμενες μετρήσεις σε baremetal περιβάλλον.
